---
title: 008. k_means
date: 2022-06-15 09:43:51
categories: 机器学习
tags:
- 机器学习
- python
---
这是在学习《机器学习基础》课程的**聚类**这一章时，做的课堂实践内容，详见《机器学习（周立华）》第九章，记录一下以便回顾。
数据集使用 [CIFAR-10数据集](http://www.cs.toronto.edu/~kriz/cifar.html)
完整代码见github：[聚类和k均值算法课程实践](https://github.com/KennanYang/mechine-learning/blob/master/week11_k_means.ipynb)


## 机器学习算法基础
### 聚类任务和k-means算法
**聚类（Clustering）** 是一种无监督学习。目的是通过对**未标记训练样本**的学习来解释数据的固有属性和规律，为进一步的数据分析提供基础。
通过对数据集进行划分，形成**簇结构（cluster）**。
实验采用 **k-means算法** 对数据集进行分割。
给定样本集D，**k-means**算法使平方误差最小化
![平方误差](https://pic.imgdb.cn/item/62a9499d09475431298ce88d.png)
对于聚类得到的聚类划分$C={C_1,C_2，…，C_k}$，其中$μ_i=1/(| C_i |)∑_(x∈C_i)$, x是聚类C的均值向量。该公式描述了聚类中样本与聚类均值向量之间的密切程度。

E值越小，表示聚类中样本的相似性越高。

K-means采用贪心策略通过迭代优化来逼近该公式。在迭代更新过程中，每个聚类中的样本与平均向量之间的距离会变短。这个距离可以用不同的范式来计算。

当达到调整范围的阈值时，停止迭代，输出一个近似最优的聚类分类结果。在本实验中，该阈值被设置为0.0001。

### DBI评价指标
对于聚类结果，我们需要通过一些性能指标来评估其质量。

本实验使用内部指标 **Davies-Bouldin（DB）指数** 来衡量聚类的性能。
**DB指数**的思想是希望C簇中样本之间的平均距离之和尽可能小，不同簇的中心点之间的距离尽可能大。
这意味着聚类分类后的样本更加集中。使聚类结果具有较高的“簇**内**相似度”和较低的“簇**间**相似度”。
DBI算法如下:
Davies-Bouldin指数:
![DBI](https://pic.imgdb.cn/item/62a9540c09475431299ab059.png)
C类样本间的平均距离:
![avg](https://pic.imgdb.cn/item/62a9543a09475431299b0a55.png)
簇C_i的中心点到簇C_j的距离:
![dist](https://pic.imgdb.cn/item/62a9543a09475431299b0acc.png)
$dist(·，·)$用于计算两个样本之间的距离，这里的距离计算采用欧氏距离，即p=2;

![disted](https://pic.imgdb.cn/item/62a9543b09475431299b0b02.png)
μ表示簇C的中心点:
![u](https://pic.imgdb.cn/item/62a954c909475431299c02db.png)
## 实验结果展示
JupyterLab的python程序运行结果如下：
![result_k_means](https://pic.imgdb.cn/item/62a9550c09475431299c84f6.png)

首先，展示测试图像。每个标签显示5个图片，10个标签有10列。

然后信息按顺序显示:
当k为6到10，范数为L1或L2时，DBI是不同的。
展示最小的DBI和最佳的聚类分区。
最后给出DBI最小的簇的图像。每个标签显示5张图片，k个标签有k列。

注: 由于初始均值向量是随机选择的，因此DBI结果略有不同。由于最小DBI的聚类结果相同，对聚类结果没有影响。当初始均值向量选择相同时，DBI结果相同。

## 参考资料
1.	CIFAR-10数据集下载: http://www.cs.toronto.edu/~kriz/cifar.html
2.	《机器学习（周立华）》（西瓜书）

